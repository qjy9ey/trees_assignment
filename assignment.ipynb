{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qjy9ey/trees_assignment/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOn7aPm2jXWv"
      },
      "source": [
        "# Assignment: Trees\n",
        "\n",
        "## Do two questions in total: \"Q1+Q2\" or \"Q1+Q3\"\n",
        "\n",
        "`! git clone https://github.com/ds3001f25/linear_models_assignment.git`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g7SyQwjjXWx"
      },
      "source": [
        "**Q1.** Please answer the following questions in your own words.\n",
        "1. Why is the Gini a good loss function for categorical target variables?\n",
        "2. Why do trees tend to overfit, and how can this tendency be constrained?\n",
        "3. True or false, and explain: Trees only really perform well in situations with lots of categorical variables as features/covariates.\n",
        "4. Why don't most versions of classification/regression tree concept allow for more than two branches after a split?\n",
        "5. What are some heuristic ways you can examine a tree and decide whether it is probably over- or under-fitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   The Gini index works well for categorical targets because it measures how mixed the classes are within that node. The Gini score goes down when one class dominates a node, which tells the tree that it's doing a good job separating categories.\n",
        "2.   Decision trees overfit because they can split until every observation is perfectly classified even if those splits are picking up random noise. To prevent that, we can limit how deep the tree grows, require a minimum number of samples to split a node, or use ensemble methods like Random Forests that average out multiple trees.\n",
        "3.   False. Trees can handle both categorical and numerical variables. They are powerful with numerical variables because they can automatically find non-linear patterns.\n",
        "4.   Most trees use two branches because they are easier to interpret and compute faster.\n",
        "5.   If a tree is really deep, has lots of tiny branches, and performs much better on training data than on test data, it is probably overfitting. On the other hand, if the tree is very shallow and its accuracy is low for both training and test data, it's likely underfitting"
      ],
      "metadata": {
        "id": "pBMqXuRInt-c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5yabrwfjXWz"
      },
      "source": [
        "**Q2.** This is a case study about classification and regression trees.\n",
        "\n",
        "1. Load the `Breast Cancer METABRIC.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  We'll use a consistent set of feature/explanatory variables. For numeric variables, we'll include `Tumor Size`, `Lymph nodes examined positive`, `Age at Diagnosis`. For categorical variables, we'll include `Tumor Stage`, `Chemotherapy`, and `Cancer Type Detailed`. One-hot-encode the categorical variables and concatenate them with the numeric variables into a feature/covariate matrix, $X$.\n",
        "\n",
        "3. Let's predict `Overall Survival Status` given the features/covariates $X$. There are 528 missing values, unfortunately: Either drop those rows from your data or add them as a category to predict. Constrain the minimum samples per leaf to 10. Print a dendrogram of the tree. Print a confusion matrix of the algorithm's performance. What is the accuracy?\n",
        "\n",
        "4. For your model in part three, compute three statistics:\n",
        "    - The **true positive rate** or **sensitivity**:\n",
        "        $$\n",
        "        TPR = \\dfrac{TP}{TP+FN}\n",
        "        $$\n",
        "    - The **true negative rate** or **specificity**:\n",
        "        $$\n",
        "        TNR = \\dfrac{TN}{TN+FP}\n",
        "        $$\n",
        "    Does your model tend to perform better with respect to one of these metrics?\n",
        "\n",
        "5. Let's predict `Overall Survival (Months)` given the features/covariates $X$. Use the train/test split to pick the optimal `min_samples_leaf` value that gives the highest $R^2$ on the test set (it's about 110). What is the $R^2$? Plot the test values against the predicted values. How do you feel about this model for clinical purposes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlBjpN6QjXWz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iom3pMykjXWz"
      },
      "source": [
        "**Q3.** This is a case study about trees using bond rating data. This is a dataset about bond ratings for different companies, alongside a bunch of business statistics and other data. Companies often have multiple reviews at different dates. We want to predict the bond rating (AAA, AA, A, BBB, BB, B, ..., C, D). Do business fundamentals predict the company's rating?\n",
        "\n",
        "1. Load the `./data/corporate_ratings.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  Plot a histogram of the `ratings` variable. It turns out that the gradations of AAA/AA/A and BBB/BB/B and so on make it hard to get good results with trees. Collapse all AAA/AA/A ratings into just A, and similarly for B and C.\n",
        "\n",
        "3. Use all of the variables **except** Rating, Date, Name, Symbol, and Rating Agency Name. To include Sector, make a dummy/one-hot-encoded representation and include it in your features/covariates. Collect the relevant variables into a data matrix $X$.\n",
        "\n",
        "4. Do a train/test split of the data and use a decision tree classifier to predict the bond rating. Including a min_samples_leaf constraint can raise the accuracy and speed up computation time. Print a confusion matrix and the accuracy of your model. How well do you predict the different bond ratings?\n",
        "\n",
        "5. If you include the rating agency as a feature/covariate/predictor variable, do the results change? How do you interpret this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obyMOj42jXWz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}